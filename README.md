# 概要
[機械学習のための連続最適化](https://www.amazon.co.jp/exec/obidos/ASIN/406152920X/hatena-blog-22/)を参考にコードを実装
# To Do
- [x] 最急降下法
- [x] ニュートン法
- [x] 二次凸最適化以外の目的関数
- [x] 直線探索
- [ ] wolf条件の失敗した時の挙動についてのパラメータ探索について
- [ ] result型の作成(return として評価回数, iteration num, assertion flag) 
- [ ] logginの作成
- [ ] AdaBoostの実装(PRML記述)
- [ ] Simple Back Propagation Algorithmの実装
- [ ] ニュートン法派生系の実装(修正ニュートン法,GN method etc...)
- [ ] 準ニュートン法
- [ ] 共役勾配法
- [ ] 制約あり最適化アルゴリズム
- [ ] ユニットテスト
- [ ] 可視化コード
- [ ] Pytorch auto gradを用いてgradient, hessian を陽に書かなくても最適化を実行できるように改良